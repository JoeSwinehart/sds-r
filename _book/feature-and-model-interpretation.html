<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>5.3 Feature and model interpretation | Social Data Science with R</title>
  <meta name="description" content="This is basically course notes corresponding to a series of courses in educational data science, which are generally applicable to a wide range of social data science problems, taught through R." />
  <meta name="generator" content="bookdown 0.21 and GitBook 2.6.7" />

  <meta property="og:title" content="5.3 Feature and model interpretation | Social Data Science with R" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="This is basically course notes corresponding to a series of courses in educational data science, which are generally applicable to a wide range of social data science problems, taught through R." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="5.3 Feature and model interpretation | Social Data Science with R" />
  
  <meta name="twitter:description" content="This is basically course notes corresponding to a series of courses in educational data science, which are generally applicable to a wide range of social data science problems, taught through R." />
  

<meta name="author" content="Daniel Anderson" />
<meta name="author" content="Brendan Cullen" />
<meta name="author" content="Ouafaa Hmaddi" />


<meta name="date" content="2020-11-13" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="random-forests.html"/>
<link rel="next" href="introduction-to-r.html"/>
<script src="assets/jquery-2.2.3/jquery.min.js"></script>
<link href="assets/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="assets/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="assets/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="assets/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="assets/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="assets/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="assets/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<script src="assets/accessible-code-block-0.0.1/empty-anchor.js"></script>
<script src="assets/core-js-2.5.3/shim.min.js"></script>
<script src="assets/react-16.12.0/react.min.js"></script>
<script src="assets/react-16.12.0/react-dom.min.js"></script>
<script src="assets/reactwidget-1.0.0/react-tools.js"></script>
<script src="assets/htmlwidgets-1.5.1/htmlwidgets.js"></script>
<script src="assets/reactable-binding-0.2.0/reactable.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/iframe-resizer/3.5.16/iframeResizer.min.js" type="text/javascript"></script>


<style type="text/css">
code.sourceCode > span { display: inline-block; line-height: 1.25; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Preface</a></li>
<li class="chapter" data-level="2" data-path="welcome.html"><a href="welcome.html"><i class="fa fa-check"></i><b>2</b> Welcome</a></li>
<li class="chapter" data-level="3" data-path="feature-engineering.html"><a href="feature-engineering.html"><i class="fa fa-check"></i><b>3</b> Feature Engineering</a><ul>
<li class="chapter" data-level="3.1" data-path="basics-of-recipes.html"><a href="basics-of-recipes.html"><i class="fa fa-check"></i><b>3.1</b> Basics of {recipes}</a></li>
<li class="chapter" data-level="3.2" data-path="creating-a-recipe.html"><a href="creating-a-recipe.html"><i class="fa fa-check"></i><b>3.2</b> Creating a recipe</a><ul>
<li class="chapter" data-level="3.2.1" data-path="creating-a-recipe.html"><a href="creating-a-recipe.html#order-matters"><i class="fa fa-check"></i><b>3.2.1</b> Order matters</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="encoding-categorical-data.html"><a href="encoding-categorical-data.html"><i class="fa fa-check"></i><b>3.3</b> Encoding categorical data</a><ul>
<li class="chapter" data-level="3.3.1" data-path="encoding-categorical-data.html"><a href="encoding-categorical-data.html#transformations-beyond-dummy-coding"><i class="fa fa-check"></i><b>3.3.1</b> Transformations beyond dummy coding</a></li>
<li class="chapter" data-level="3.3.2" data-path="encoding-categorical-data.html"><a href="encoding-categorical-data.html#handling-new-levels"><i class="fa fa-check"></i><b>3.3.2</b> Handling new levels</a></li>
<li class="chapter" data-level="3.3.3" data-path="encoding-categorical-data.html"><a href="encoding-categorical-data.html#final-thoughts-on-encoding-categorical-data"><i class="fa fa-check"></i><b>3.3.3</b> Final thoughts on encoding categorical data</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="dealing-with-low-variance-predictors.html"><a href="dealing-with-low-variance-predictors.html"><i class="fa fa-check"></i><b>3.4</b> Dealing with low variance predictors</a></li>
<li class="chapter" data-level="3.5" data-path="missing-data.html"><a href="missing-data.html"><i class="fa fa-check"></i><b>3.5</b> Missing data</a><ul>
<li class="chapter" data-level="3.5.1" data-path="missing-data.html"><a href="missing-data.html#missing-data-via-recipes"><i class="fa fa-check"></i><b>3.5.1</b> Missing data via {recipes}</a></li>
<li class="chapter" data-level="3.5.2" data-path="missing-data.html"><a href="missing-data.html#a-few-words-of-caution"><i class="fa fa-check"></i><b>3.5.2</b> A few words of caution</a></li>
</ul></li>
<li class="chapter" data-level="3.6" data-path="transformations.html"><a href="transformations.html"><i class="fa fa-check"></i><b>3.6</b> Transformations</a><ul>
<li class="chapter" data-level="3.6.1" data-path="transformations.html"><a href="transformations.html#box-cox-and-similar-transformations"><i class="fa fa-check"></i><b>3.6.1</b> Box-Cox and similar transformations</a></li>
<li class="chapter" data-level="3.6.2" data-path="transformations.html"><a href="transformations.html#an-applied-example"><i class="fa fa-check"></i><b>3.6.2</b> An applied example</a></li>
</ul></li>
<li class="chapter" data-level="3.7" data-path="nonlinearity.html"><a href="nonlinearity.html"><i class="fa fa-check"></i><b>3.7</b> Nonlinearity</a><ul>
<li class="chapter" data-level="3.7.1" data-path="nonlinearity.html"><a href="nonlinearity.html#polynomial-transformations"><i class="fa fa-check"></i><b>3.7.1</b> Polynomial transformations</a></li>
<li class="chapter" data-level="3.7.2" data-path="nonlinearity.html"><a href="nonlinearity.html#splines"><i class="fa fa-check"></i><b>3.7.2</b> Splines</a></li>
</ul></li>
<li class="chapter" data-level="3.8" data-path="interactions.html"><a href="interactions.html"><i class="fa fa-check"></i><b>3.8</b> Interactions</a><ul>
<li class="chapter" data-level="3.8.1" data-path="interactions.html"><a href="interactions.html#creating-interactions-by-hand"><i class="fa fa-check"></i><b>3.8.1</b> Creating interactions “by hand”</a></li>
<li class="chapter" data-level="3.8.2" data-path="interactions.html"><a href="interactions.html#creating-interactions-with-recipes"><i class="fa fa-check"></i><b>3.8.2</b> Creating interactions with {recipes}</a></li>
</ul></li>
<li class="chapter" data-level="3.9" data-path="pca.html"><a href="pca.html"><i class="fa fa-check"></i><b>3.9</b> PCA</a><ul>
<li class="chapter" data-level="3.9.1" data-path="pca.html"><a href="pca.html#pca-with-recipes"><i class="fa fa-check"></i><b>3.9.1</b> PCA with {recipes}</a></li>
</ul></li>
<li class="chapter" data-level="3.10" data-path="wrapping-up.html"><a href="wrapping-up.html"><i class="fa fa-check"></i><b>3.10</b> Wrapping up</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="decision-trees.html"><a href="decision-trees.html"><i class="fa fa-check"></i><b>4</b> Decision Trees</a><ul>
<li class="chapter" data-level="4.0.1" data-path="decision-trees.html"><a href="decision-trees.html#a-simple-decision-tree"><i class="fa fa-check"></i><b>4.0.1</b> A simple decision tree</a></li>
<li class="chapter" data-level="4.1" data-path="determining-optimal-splits.html"><a href="determining-optimal-splits.html"><i class="fa fa-check"></i><b>4.1</b> Determining optimal splits</a></li>
<li class="chapter" data-level="4.2" data-path="visualizing-decision-trees.html"><a href="visualizing-decision-trees.html"><i class="fa fa-check"></i><b>4.2</b> Visualizing decision trees</a></li>
<li class="chapter" data-level="4.3" data-path="fitting-a-decision-tree.html"><a href="fitting-a-decision-tree.html"><i class="fa fa-check"></i><b>4.3</b> Fitting a decision tree</a><ul>
<li class="chapter" data-level="4.3.1" data-path="fitting-a-decision-tree.html"><a href="fitting-a-decision-tree.html#load-the-data"><i class="fa fa-check"></i><b>4.3.1</b> Load the data</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="tuning-decision-trees.html"><a href="tuning-decision-trees.html"><i class="fa fa-check"></i><b>4.4</b> Tuning decision trees</a><ul>
<li class="chapter" data-level="4.4.1" data-path="tuning-decision-trees.html"><a href="tuning-decision-trees.html#decision-tree-hyperparamters"><i class="fa fa-check"></i><b>4.4.1</b> Decision tree hyperparamters</a></li>
<li class="chapter" data-level="4.4.2" data-path="tuning-decision-trees.html"><a href="tuning-decision-trees.html#conducting-the-grid-search"><i class="fa fa-check"></i><b>4.4.2</b> Conducting the grid search</a></li>
<li class="chapter" data-level="4.4.3" data-path="tuning-decision-trees.html"><a href="tuning-decision-trees.html#finalizing-our-model-fit"><i class="fa fa-check"></i><b>4.4.3</b> Finalizing our model fit</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="bagging-and-random-forests.html"><a href="bagging-and-random-forests.html"><i class="fa fa-check"></i><b>5</b> Bagging and Random Forests</a><ul>
<li class="chapter" data-level="5.0.1" data-path="bagging-and-random-forests.html"><a href="bagging-and-random-forests.html#bagging-by-hand"><i class="fa fa-check"></i><b>5.0.1</b> Bagging “by hand”</a></li>
<li class="chapter" data-level="5.1" data-path="bagged-trees.html"><a href="bagged-trees.html"><i class="fa fa-check"></i><b>5.1</b> Bagged trees</a><ul>
<li class="chapter" data-level="5.1.1" data-path="bagged-trees.html"><a href="bagged-trees.html#working-with-out-of-bag-samples"><i class="fa fa-check"></i><b>5.1.1</b> Working with out of bag samples</a></li>
<li class="chapter" data-level="5.1.2" data-path="bagged-trees.html"><a href="bagged-trees.html#tuning-with-oob-samples"><i class="fa fa-check"></i><b>5.1.2</b> Tuning with OOB samples</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="random-forests.html"><a href="random-forests.html"><i class="fa fa-check"></i><b>5.2</b> Random Forests</a><ul>
<li class="chapter" data-level="5.2.1" data-path="random-forests.html"><a href="random-forests.html#fitting-random-forests"><i class="fa fa-check"></i><b>5.2.1</b> Fitting random forests</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="feature-and-model-interpretation.html"><a href="feature-and-model-interpretation.html"><i class="fa fa-check"></i><b>5.3</b> Feature and model interpretation</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="introduction-to-r.html"><a href="introduction-to-r.html"><i class="fa fa-check"></i><b>6</b> Introduction to R</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Social Data Science with R</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="feature-and-model-interpretation" class="section level2">
<h2><span class="header-section-number">5.3</span> Feature and model interpretation</h2>
<p>A considerable benefit of decision tree model is that they are relatively easy to understand, in terms of how predictions are made. It’s perhaps less clear <em>why</em> specific splits have been made, but it’s relatively straightforward to communicate with stakeholders <em>how</em> predictions are made. This is because the tree itself can be followed, like a road map, to the terminal node. The tree is just a series of if/then statements. Unfortunately, this ease of interpretation all goes out the window with bagged trees and random forests. Instead of just building one decision tree, we are building hundreds or even thousands, with each tree (or at least most trees) being at least slightly different. So how do we communicate the results of our model with stakeholders? How can we effectively convey how our model makes predictions?</p>
<p>Perhaps the most straightforward way to communicate complex models with stakeholders is to focus on feature importance. That is, which features in the model are <strong>most important</strong> in establishing the prediction. We can do this with <strong>{ranger}</strong> models using the <a href="https://koalaverse.github.io/vip/index.html"><strong>{vip}</strong></a> package (vip stands for <strong>v</strong>ariable <strong>i</strong>mportance <strong>p</strong>lots).</p>
<p>In a standard decision, a variable is selected at a given node if it improves the objective function score. The relative importance of a given variable is then determined by the sum of the squared improvements (see <a href="https://koalaverse.github.io/vip/articles/vip.html"><strong>{vip}</strong> documentation</a>). This basic idea is extended to ensembles of trees, like bagged trees and random forest, by computing the mean of these importance scores across all trees in the ensemble.</p>
<p>To obtain variable importance scores, we first have to re-run our <strong>{ranger}</strong> model, requesting it compute variable importance metrics. We do this by specifying <code>importance = "impurity"</code> (which is the Gini index for classification problems).</p>
<div class="sourceCode" id="cb306"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb306-1"><a href="feature-and-model-interpretation.html#cb306-1"></a><span class="co"># specify the model and request a variable importance metric</span></span>
<span id="cb306-2"><a href="feature-and-model-interpretation.html#cb306-2"></a>rf_mod_reg_final &lt;-<span class="st"> </span><span class="kw">rand_forest</span>() <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb306-3"><a href="feature-and-model-interpretation.html#cb306-3"></a><span class="st">    </span><span class="kw">set_mode</span>(<span class="st">&quot;regression&quot;</span>) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb306-4"><a href="feature-and-model-interpretation.html#cb306-4"></a><span class="st">    </span><span class="kw">set_engine</span>(<span class="st">&quot;ranger&quot;</span>) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb306-5"><a href="feature-and-model-interpretation.html#cb306-5"></a><span class="st">    </span><span class="kw">set_args</span>(<span class="dt">mtry =</span> rf_reg_fits2<span class="op">$</span>mtry[<span class="dv">1</span>],</span>
<span id="cb306-6"><a href="feature-and-model-interpretation.html#cb306-6"></a>             <span class="dt">min_n =</span> rf_reg_fits2<span class="op">$</span>min_n[<span class="dv">1</span>],</span>
<span id="cb306-7"><a href="feature-and-model-interpretation.html#cb306-7"></a>             <span class="dt">trees =</span> <span class="dv">1000</span>,</span>
<span id="cb306-8"><a href="feature-and-model-interpretation.html#cb306-8"></a>             <span class="dt">importance =</span> <span class="st">&quot;impurity&quot;</span>)</span>
<span id="cb306-9"><a href="feature-and-model-interpretation.html#cb306-9"></a></span>
<span id="cb306-10"><a href="feature-and-model-interpretation.html#cb306-10"></a><span class="co"># fit the model</span></span>
<span id="cb306-11"><a href="feature-and-model-interpretation.html#cb306-11"></a>rf_fit_reg_final &lt;-<span class="st"> </span><span class="kw">fit</span>(rf_mod_reg_final,</span>
<span id="cb306-12"><a href="feature-and-model-interpretation.html#cb306-12"></a>                        score <span class="op">~</span><span class="st"> </span>.,</span>
<span id="cb306-13"><a href="feature-and-model-interpretation.html#cb306-13"></a>                        processed_reg)</span></code></pre></div>
<p>And now we can request variable importance <em>scores</em> with <code>vip::vi()</code>, or a variable importance <em>plot</em> with <code>vip::vip()</code>. Let’s first look at the scores.</p>
<div class="sourceCode" id="cb307"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb307-1"><a href="feature-and-model-interpretation.html#cb307-1"></a><span class="kw">library</span>(vip)</span>
<span id="cb307-2"><a href="feature-and-model-interpretation.html#cb307-2"></a><span class="kw">vi</span>(rf_fit_reg_final<span class="op">$</span>fit)</span></code></pre></div>
<pre><code>## # A tibble: 31 x 2
##    Variable    Importance
##    &lt;chr&gt;            &lt;dbl&gt;
##  1 enrl_grd      7574484.
##  2 tag_ed_fg     6912953.
##  3 econ_dsvntg   6686036.
##  4 sp_ed_fg      5728096.
##  5 lon           4258608.
##  6 lat           4057123.
##  7 time_index    3781738.
##  8 tst_bnch      3715267.
##  9 ayp_lep       3672420.
## 10 ethnic_cd     2556395.
## # … with 21 more rows</code></pre>
<p>The results of this investigation are not entirely surprising. The <code>enrl_grd</code> the student is in is the most important predictor of their score. Following grade level, the students’ economic disadvantaged status is the most predictive feature in the model, following <a href="https://static1.squarespace.com/static/592b5bbfd482e9898c67fd98/t/5e6582fd24dfaf352639d205/1583710974310/The+Widening+Income+Acheivement+Gap+Between+the+Rich+and+The+Poor.pdf">a long history</a> of evidence documenting differential achievement by socioeconomic status. Students classified as talented and gifted (TAG), and those who received special education services are the next two most predictive variables, followed by the physical location of the school (<code>lat</code> = latitude and <code>lon</code> = longitude). Each of these variables would be among those that we might have guessed, a priori, would be the most predictive.</p>
<p>Let’s look at a plot showing the relative importance of the features in our model.</p>
<div class="sourceCode" id="cb309"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb309-1"><a href="feature-and-model-interpretation.html#cb309-1"></a><span class="kw">vip</span>(rf_fit_reg_final<span class="op">$</span>fit)</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-202-1.png" width="672" /></p>
<p>Our inferences here are similar, but this view helps us see more clearly that the first three variables are similarly important, then there is a bit of a dip for with special education status, followed by a sizeable dip for latitude and longitude. The <code>tst_bnch</code> feature is essentially a categorical version of grade level (so we are modeling it as both a continuous and categorical feature; the merits of such an approach could be argued, but we see that we are getting improvements from both versions).</p>
<p>With bagged trees and random forests, we can also look at variable importance in a slightly different way. Rather than summing the contributions for each tree, and taking the average across trees, we can compute the OOB error for a given tree, then shuffle the values for a given variable and re-compute the OOB error. If the variable is important, the OOB error will increase as we perturb the given variable, but otherwise the error will stay (approximately) the same (<a href="https://bmcbioinformatics.biomedcentral.com/track/pdf/10.1186/s12859-016-0995-8.pdf">see Wright, Ziegler, and König, 2016</a>).</p>
<p>To get this <em>purmutation</em>-based importance measure, we just change <code>importance</code> to <code>"purmutation"</code>. Let’s do this and see if the resulting plot differs.</p>
<div class="sourceCode" id="cb310"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb310-1"><a href="feature-and-model-interpretation.html#cb310-1"></a>rf_mod_reg_final2 &lt;-<span class="st"> </span><span class="kw">rand_forest</span>() <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb310-2"><a href="feature-and-model-interpretation.html#cb310-2"></a><span class="st">    </span><span class="kw">set_mode</span>(<span class="st">&quot;regression&quot;</span>) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb310-3"><a href="feature-and-model-interpretation.html#cb310-3"></a><span class="st">    </span><span class="kw">set_engine</span>(<span class="st">&quot;ranger&quot;</span>) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb310-4"><a href="feature-and-model-interpretation.html#cb310-4"></a><span class="st">    </span><span class="kw">set_args</span>(<span class="dt">mtry =</span> rf_reg_fits2<span class="op">$</span>mtry[<span class="dv">1</span>],</span>
<span id="cb310-5"><a href="feature-and-model-interpretation.html#cb310-5"></a>             <span class="dt">min_n =</span> rf_reg_fits2<span class="op">$</span>min_n[<span class="dv">1</span>],</span>
<span id="cb310-6"><a href="feature-and-model-interpretation.html#cb310-6"></a>             <span class="dt">trees =</span> <span class="dv">1000</span>,</span>
<span id="cb310-7"><a href="feature-and-model-interpretation.html#cb310-7"></a>             <span class="dt">importance =</span> <span class="st">&quot;purmutation&quot;</span>)</span>
<span id="cb310-8"><a href="feature-and-model-interpretation.html#cb310-8"></a></span>
<span id="cb310-9"><a href="feature-and-model-interpretation.html#cb310-9"></a>rf_fit_reg_final2 &lt;-<span class="st"> </span><span class="kw">fit</span>(rf_mod_reg_final,</span>
<span id="cb310-10"><a href="feature-and-model-interpretation.html#cb310-10"></a>                        score <span class="op">~</span><span class="st"> </span>.,</span>
<span id="cb310-11"><a href="feature-and-model-interpretation.html#cb310-11"></a>                        processed_reg)</span>
<span id="cb310-12"><a href="feature-and-model-interpretation.html#cb310-12"></a></span>
<span id="cb310-13"><a href="feature-and-model-interpretation.html#cb310-13"></a><span class="kw">vip</span>(rf_fit_reg_final2<span class="op">$</span>fit)</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-203-1.png" width="672" /></p>
<p>As we can see, there are a few small differences, but generally the results agree, providing us with greater confidence in the ordering variable importance. If the results did not generally align that may be evidence that our model is unstable and we would likely want to probe our model a bit more.</p>
<p>Inspecting variable importance helps us understand <em>which</em> variables contribute to our model predictions, but not necessarily <em>how</em> they relate to the outcome. For that, we can look at partial dependency plots via the <a href="https://bgreenwell.github.io/pdp/index.html"><strong>{pdp}</strong></a> package (which is developed by the same people who created <strong>{vip}</strong>).</p>
<p>Partial dependency plots show the <em>marginal</em> effect of a feature on the outcome. This can help us to understand the directionality of the effect and whether it is generally linear or not. For example, we would probably expect that students’ scores would increase roughly linearly and monotonically with <code>enrl_grd</code>. To see if that’s the case we case we use the <code>pdp::partial()</code> function.</p>
<div class="sourceCode" id="cb311"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb311-1"><a href="feature-and-model-interpretation.html#cb311-1"></a><span class="kw">library</span>(pdp)</span>
<span id="cb311-2"><a href="feature-and-model-interpretation.html#cb311-2"></a><span class="kw">partial</span>(rf_fit_reg_final<span class="op">$</span>fit, </span>
<span id="cb311-3"><a href="feature-and-model-interpretation.html#cb311-3"></a>        <span class="dt">pred.var =</span> <span class="st">&quot;enrl_grd&quot;</span>,</span>
<span id="cb311-4"><a href="feature-and-model-interpretation.html#cb311-4"></a>        <span class="dt">train =</span> processed_reg,</span>
<span id="cb311-5"><a href="feature-and-model-interpretation.html#cb311-5"></a>        <span class="dt">plot =</span> <span class="ot">TRUE</span>,</span>
<span id="cb311-6"><a href="feature-and-model-interpretation.html#cb311-6"></a>        <span class="dt">plot.engine =</span> <span class="st">&quot;ggplot2&quot;</span>)</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-204-1.png" width="672" /></p>
<p>And we can see that, yes, the relation is roughly linear and monotonically increasing.</p>
<p>What if we want to explore more than one variable? Let’s look at the geographic location of the school.</p>
<div class="sourceCode" id="cb312"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb312-1"><a href="feature-and-model-interpretation.html#cb312-1"></a><span class="kw">partial</span>(rf_fit_reg_final<span class="op">$</span>fit, </span>
<span id="cb312-2"><a href="feature-and-model-interpretation.html#cb312-2"></a>        <span class="dt">pred.var =</span> <span class="kw">c</span>(<span class="st">&quot;lon&quot;</span>, <span class="st">&quot;lat&quot;</span>),</span>
<span id="cb312-3"><a href="feature-and-model-interpretation.html#cb312-3"></a>        <span class="dt">train =</span> processed_reg,</span>
<span id="cb312-4"><a href="feature-and-model-interpretation.html#cb312-4"></a>        <span class="dt">plot =</span> <span class="ot">TRUE</span>,</span>
<span id="cb312-5"><a href="feature-and-model-interpretation.html#cb312-5"></a>        <span class="dt">plot.engine =</span> <span class="st">&quot;ggplot2&quot;</span>)</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-205-1.png" width="672" /></p>
<p>Because this is geographic data, and we know the data come from Oregon (although they are simulated) we can interpret this as if we were looking at a physical map. One notable aspect is that there is a fairly clear band running north/south in the western part of the state. This is roughly where I-5 runs and where many of the more populous towns/cities are located, including Ashland/Medford in the south, Eugene around the center, and Portland in the north. We could even overlay an image of Oregon here, which actually helps us with interpretation a bit more.</p>
<p><img src="_main_files/figure-html/unnamed-chunk-206-1.png" width="672" />
Note that, when the PDP is created, it just create a grid for prediction. So when we overlay the map of Oregon, we see some areas where the prediction extends outside of the state, which are not particularly trustworthy.</p>
<p>Finally, we might also be interested in the individual variability of a feature. Let’s again look at the enrolled grade of students. In this case, we’ll create <em>individual conditional expectation</em> plots, or ICE curves, which are the equivalent to PDP’s but for individual observations. The <strong>{pdp}</strong> package can again create these for us. The process for creating them is essentially equivalent, but we provide one additional argument, <code>ice = TRUE</code>. Note that we can use <code>plot = TRUE</code> here too but I’ve just output the values to have a bit more control of how the plot renders.</p>
<div class="sourceCode" id="cb313"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb313-1"><a href="feature-and-model-interpretation.html#cb313-1"></a>ice_grade &lt;-<span class="st"> </span><span class="kw">partial</span>(rf_fit_reg_final<span class="op">$</span>fit, </span>
<span id="cb313-2"><a href="feature-and-model-interpretation.html#cb313-2"></a>                     <span class="dt">pred.var =</span> <span class="st">&quot;enrl_grd&quot;</span>,</span>
<span id="cb313-3"><a href="feature-and-model-interpretation.html#cb313-3"></a>                     <span class="dt">train =</span> processed_reg,</span>
<span id="cb313-4"><a href="feature-and-model-interpretation.html#cb313-4"></a>                     <span class="dt">ice =</span> <span class="ot">TRUE</span>)</span>
<span id="cb313-5"><a href="feature-and-model-interpretation.html#cb313-5"></a></span>
<span id="cb313-6"><a href="feature-and-model-interpretation.html#cb313-6"></a><span class="kw">ggplot</span>(ice_grade, <span class="kw">aes</span>(enrl_grd, yhat)) <span class="op">+</span></span>
<span id="cb313-7"><a href="feature-and-model-interpretation.html#cb313-7"></a><span class="st">  </span><span class="kw">geom_line</span>(<span class="kw">aes</span>(<span class="dt">group =</span> yhat.id),</span>
<span id="cb313-8"><a href="feature-and-model-interpretation.html#cb313-8"></a>            <span class="dt">color =</span> <span class="st">&quot;gray40&quot;</span>,</span>
<span id="cb313-9"><a href="feature-and-model-interpretation.html#cb313-9"></a>            <span class="dt">size =</span> <span class="fl">0.1</span>,</span>
<span id="cb313-10"><a href="feature-and-model-interpretation.html#cb313-10"></a>            <span class="dt">alpha =</span> <span class="fl">0.1</span>) <span class="op">+</span></span>
<span id="cb313-11"><a href="feature-and-model-interpretation.html#cb313-11"></a><span class="st">  </span><span class="kw">stat_summary</span>(<span class="dt">geom =</span> <span class="st">&quot;line&quot;</span>, <span class="dt">fun =</span> <span class="st">&quot;mean&quot;</span>)</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-207-1.png" width="672" /></p>
<p>And as we would likely expect, there is a <em>lot</em> of variation here in expected scores across grades.</p>
<p>Bagged trees can often lead to better predictions than a single decision tree by creating <em>ensembles</em> of trees based on bootstrap resamples of the data and aggregating the results across all trees. Random forests extend this framework by randomly sample <span class="math inline">\(m\)</span> columns at each split of each tree that is grown in the ensemble (or forest) which can help decorrelate the trees and, often, lead to better overall predictions. Unfortunately creating an ensemble of trees also makes feature and model interpretation a bit more difficult. Tools like variable importance and partial dependence plots can be an efficient means of communicating <em>how</em> and <em>why</em> a model is making the predictions it is, while still maintaining strong overall model performance. For more information on these and other methods, see <a href="https://christophm.github.io/interpretable-ml-book/">Molnar, 2020</a>.</p>

</div>
<!-- </div> -->
            </section>

          </div>
        </div>
      </div>
<a href="random-forests.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="introduction-to-r.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="assets/gitbook-2.6.7/js/app.min.js"></script>
<script src="assets/gitbook-2.6.7/js/lunr.js"></script>
<script src="assets/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="assets/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="assets/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="assets/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="assets/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="assets/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="assets/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "subsection"
},
"toolbar": {
"position": "static"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
